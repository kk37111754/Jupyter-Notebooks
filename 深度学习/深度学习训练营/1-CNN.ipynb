{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb7c91a",
   "metadata": {},
   "source": [
    "# 0. CNN 引入 - 基础\n",
    "\n",
    "### 卷积神经网络 (CNN) 入门\n",
    "\n",
    "\n",
    "首先简要介绍人工神经网络（ Artificial Neural Networks），也称为 ANN。\n",
    "\n",
    "很多机器学习算法的灵感来自大自然，最大的灵感来自我们的大脑，我们如何思考、学习和做出决定。\n",
    "\n",
    "有趣的是，当我们触摸热的东西时，我们体内的神经元如何将信号传递给大脑。大脑然后产生从热区撤退的冲动。我们已经根据经验接受了培训。根据我们的经验，我们开始做出更好的决定。\n",
    "\n",
    "使用相同的类比，当我们向神经网络发送输入（触摸热物质）时，然后基于学习（以前的经验）我们产生输出（退出热区域）。将来当我们得到类似的信号（触摸热表面）时，我们可以预测输出（从热区撤出）。\n",
    "\n",
    "\n",
    "假设我们有温度、风速、能见度、湿度等输入来预测我们将遇到什么样的天气——下雨、多云或晴天。\n",
    "\n",
    "\n",
    "![b0A5rx](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/b0A5rx.jpg)\n",
    "\n",
    "\n",
    "让我们使用神经网络来表示这一点，并了解神经网络的组成部分。\n",
    "神经网络接收输入，通过使用激活函数改变状态来转换输入信号以产生输出。\n",
    "\n",
    "输出将根据接收到的输入、强度（如果信号由权重表示）以及应用于输入参数和权重的激活而变化。\n",
    "\n",
    "神经网络与我们神经系统中的神经元非常相似。\n",
    "\n",
    "![MGk8JF](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/MGk8JF.jpg)\n",
    "\n",
    "x1, x2, ...xn 是树突的输入信号，在神经元的轴突末端会发生状态变化以产生输出 y1, y2,...yn。\n",
    "\n",
    "\n",
    "以我们预测天气为例，其中温度、风速、能见度和湿度是输入参数。这些输入然后由神经元通过使用激活函数在输入上应用权重来处理以产生输出。这里的预测输出是天气类型——晴天、雨天或阴天。\n",
    "\n",
    "![n4rg1w](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/n4rg1w.jpg)\n",
    "\n",
    "w1, w2, w3 and w4 are the weights applied to the neurons and ɸ is the activation function.\n",
    "\n",
    "\n",
    "那么，神经网络的组成部分是什么，神经网络将有：\n",
    "\n",
    "* 输入层，偏置单位为1。也称为截距。\n",
    "* 一个或多个隐藏层，每个隐藏层都会有一个偏置单元\n",
    "* 输出层\n",
    "* 与每个连接相关的权重\n",
    "* 将节点的输入信号转换为输出信号的激活函数\n",
    "\n",
    "\n",
    "输入层（Input layer）、隐藏层（hidden layer）和输出层（output layers）通常称为密集层（dense layers）\n",
    "\n",
    "\n",
    "![j7pNwA](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/j7pNwA.jpg)\n",
    "\n",
    "具有输入、隐藏和输出层以及激活单元的神经网络\n",
    "\n",
    "\n",
    "这些权重是什么，激活函数是什么，这些复杂的方程是什么？\n",
    "\n",
    "* **权重**是神经网络学习的方式。我们调整权重以确定信号的强度。\n",
    "* 权重帮助我们提出不同的输出。\n",
    "    例如，要预测晴天，温度可以介于宜人到炎热之间，晴天时能见度非常好，因此温度和能见度的权重会更高。\n",
    "    湿度不会太高，否则会是潮湿的一天，因此湿度的重量可能会减少或可能是负数。\n",
    "    风速可能与晴天无关，它的强度将是 0 或非常小。\n",
    "* 我们随机初始化权重/weights（w）并将它们与输入/inputs（x）相乘并添加偏置项/ bias term（b），因此对于隐藏层，一个紧凑的版本是计算 z 然后应用激活函数/activation function（ɸ）。\n",
    "\n",
    "* 我们称之为前向传播(Forward propagation)。一个紧凑的广义方程可以表示如下，其中 `l` 为层的编号。对于输入层 `l`=1。\n",
    "\n",
    "![hFnFUH](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/hFnFUH.jpg)\n",
    "\n",
    "前向传播的紧凑方程\n",
    "\n",
    "* 激活函数，让我们了解它们的用途是什么？\n",
    "    激活函数有助于决定我们是否需要激发一个神经元，如果我们需要激发一个神经元，那么信号的强度是多少。\n",
    "    激活函数是神经元通过神经网络处理和传递信息的机制。[一个更详细的关于激活函数的例子 By 林肯](https://www.toutiao.com/article/7086766453126349352/)\n",
    "\n",
    "### 让我们用预测天气的样本数据来理解神经网络\n",
    "\n",
    "为了简化事情以便更好地理解，我们只需要两个输入：_温度_ 和 _可见性_ ，带有 2 个隐藏节点，没有偏差单元，我们仍然希望将天气分类为晴天或非晴天。\n",
    "\n",
    "![u9JPTR](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/u9JPTR.jpg)\n",
    "\n",
    "我们的温度是华氏度，能见度是英里。\n",
    "\n",
    "让我们取一个温度为 50F 且能见度为 0.01 英里的数据。\n",
    "\n",
    "\n",
    "1. 我们将权重随机初始化为接近零但不等于零的值。\n",
    "2. 接下来，我们将单个数据点与温度和能见度的输入节点一起使用，并在神经网络中移动。\n",
    "3. 从左到右应用前向传播，将权重乘以输入值，然后使用 ReLU 作为激活函数。我们知道 ReLU 是隐藏层的最佳激活函数。\n",
    "4. 我们现在预测输出并将预测输出与实际输出值进行比较。由于这是一个分类问题，我们使用交叉熵函数\n",
    "![eVIqlQ](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/eVIqlQ.jpg)\n",
    "\n",
    "    n 是数据集中的数据点总数，对训练集中的所有输入求和，y 是实际输出，y ̂ (y-hat) 是预测输出\n",
    "\n",
    "> 交叉熵是一个非负成本函数，范围在 0 到 1 之间\n",
    "\n",
    "\n",
    "    在我们的示例中，实际输出不是晴天，因此 y 的值为 0。如果 y-hat 为 1，那么让我们替换成本函数中的值，看看我们得到了什么\n",
    "\n",
    "![fptNiq](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/fptNiq.jpg)\n",
    "\n",
    "    预测输出与实际输出不同\n",
    "\n",
    "    同样，当实际输出和预测输出相同时，我们得到成本 c=0。\n",
    "\n",
    "![LnTHC9](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/LnTHC9.jpg)\n",
    "\n",
    "    预测输出与实际输出相同\n",
    "\n",
    "    我们可以看到交叉熵函数，当预测输出与实际输出匹配时，成本为零。当预测输出与实际输出不匹配时，成本为无穷大。\n",
    "\n",
    "5. 我们从右到左进行反向传播并调整权重。权重会根据权重对误差的影响程度进行调整。学习率决定了我们更新权重的程度。\n",
    "\n",
    "反向传播，学习率。我们将解释一切都是简单的术语。\n",
    "\n",
    "\n",
    "#### 反向传播（Back propagation）\n",
    "\n",
    "将反向传播视为一种反馈机制，我们有时会从父母、导师和同伴那里获得。反馈帮助我们成为一个更好的人。\n",
    "\n",
    "反向传播是一种快速的学习算法。**它告诉我们当我们改变权重和偏差时成本函数将如何变化。从而改变神经网络的行为。**\n",
    "\n",
    "无需深入了解反向传播的详细数学。在反向传播中，我们计算每个训练示例的成本（cost）相对于权重（weight）的偏导数和成本相对于偏差（bias）的偏导数。平均所有训练示例（training examples）的偏导数。\n",
    "\n",
    "对于我们的单个数据点，我们确定每个权重和偏差对误差的影响。根据权重对误差的影响，我们同时调整所有权重。\n",
    "\n",
    "\n",
    "可以使用批量梯度下降 (Batch gradient descent) 为所有训练数据更新一次权重，也可以使用随机梯度下降 (Stochastic gradient descent) 为每个训练示例更新一次权重。\n",
    "\n",
    "![j9LQMA](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/j9LQMA.jpg)\n",
    "\n",
    "\n",
    "我们使用 GD 或 SGD 对不同的权重重复第 1 步到第 5 步。\n",
    "随着权重的调整，某些节点将根据激活函数打开或关闭。\n",
    "\n",
    "\n",
    "在我们的天气示例中，温度与预测多云的相关性可能较低，因为夏季温度可能为 70+，但仍然多云，或者在寒冷的冬日温度可能为 30F 或更低，但仍然多云。在这种情况下，激活函数可以决定关闭负责温度的隐藏节点并仅打开可见性节点以预测输出为不是晴天，如下所示：\n",
    "\n",
    "![SLo81T](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/SLo81T.jpg)\n",
    "\n",
    "对于非晴天天气预报，关闭第二个节点的温度权重\n",
    "\n",
    "![geRL5X](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/geRL5X.jpg)\n",
    "\n",
    "Batch GD 在每个 epoch 后更新权重。 SGD 更新每个训练示例的权重\n",
    "\n",
    "**Epoch** 是指将完整的数据集用于一次学习，一次前向传播和一次反向传播用于所有训练示例。\n",
    "\n",
    "我们重复多个时期的前向和后向传播，直到我们收敛到全局最小值。\n",
    "\n",
    "#### 什么是学习率？\n",
    "\n",
    "* 学习率控制着我们应该根据损失梯度调整多少权重。\n",
    "* 学习率的值越低，收敛到全局最小值的速度就越慢。\n",
    "* 较高的学习率值将不允许梯度下降收敛\n",
    "* 学习率是随机初始化的。\n",
    "\n",
    "![xk3PdH](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/xk3PdH.jpg)\n",
    "\n",
    "#### 如何确定隐藏层数和每个隐藏层中的节点数？\n",
    "\n",
    "\n",
    "随着我们增加隐藏层的数量和隐藏层中的神经元或节点的数量，我们增加了神经网络的容量。神经元可以协作来表达不同的功能。这通常会导致过度拟合，我们必须小心过度拟合和欠拟合。\n",
    "\n",
    "神经网络中隐藏层的最佳数量基于 [Jeff Heaton](https://www.heatonresearch.com/) 建议的下表：\n",
    "\n",
    "| 隐藏层数量 | 结果 | 中文结果 |\n",
    "| --------- | ---- | ------- |\n",
    "| 0         | When the data is linearly separable, we do not need any hidden layer     |  当数据线性可分时，我们不需要任何隐藏层       |\n",
    "| 1         | Approximate any function that maps continues data from one finite space to another finite space     |  逼近任何映射的函数，将数据从一个有限空间延续到另一个有限空间       |\n",
    "| 2         | When we want to represent an arbitrary decision boundary to arbitrary accuracy with rational activation functions and can approximate any smooth mapping to any accuracy. Example: for time series related data     | 当我们想用有理激活函数将任意决策边界表示为任意精度并且可以将任何平滑映射逼近到任意精度时。示例：对于时间序列，相关数据        |\n",
    "| >2        |  For complex representations. Example deep learning like CNN,RNN    |   对于复杂的表示。深度学习示例，如 CNN、RNN      |\n",
    "\n",
    "\n",
    "对于隐藏层中的最佳神经元数量，我们可以遵循以下任何一种方法\n",
    "\n",
    "* 输入和输出层中神经元数量的平均值。\n",
    "* 在输入层的大小和输出层的大小之间。\n",
    "* 输入层大小的 2/3，加上输出层的大小。\n",
    "* 小于输入层大小的两倍。\n",
    "\n",
    "这是一种在不深入复杂数学的情况下以简单的方式解释人工神经网络的努力。\n",
    "\n",
    "### 让我们了解我们的大脑如何识别图像 \n",
    "\n",
    "根据诺贝尔奖获得者Hubel和Wiesel的说法，视觉区域V1由简单细胞和复杂细胞组成。\n",
    "\n",
    "简单单元有助于特征检测，而复杂单元结合了来自小空间邻域的几个这样的局部特征。空间池有助于平移不变特征。\n",
    "\n",
    "当我们看到一个新图像时，我们可能会从左到右和从上到下扫描图像，以了解图像的不同特征。我们的下一步是结合我们扫描的不同局部特征来对图像进行分类。 这正是 CNN 的工作原理。\n",
    "\n",
    "#### 平移不变特征是什么意思？\n",
    "\n",
    "图像的不变性意味着即使图像被旋转、大小不同或在不同的照明下观察，物体也会被识别为同一物体。\n",
    "\n",
    "![Igh1R8](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Igh1R8.jpg)\n",
    "不变性——即使旋转、收缩，玫瑰也是玫瑰\n",
    "\n",
    "这有助于对象识别，因为图像表示对于图像变换（例如平移、旋转或小变形等）是不变的。\n",
    "\n",
    "我们使用卷积神经网络进行图像识别和分类。\n",
    "\n",
    "让我们了解什么是 CNN 以及我们如何使用它。\n",
    "\n",
    "## 什么是CNN？\n",
    "\n",
    "CNN（ Convolutional Neural Network） 代表卷积神经网络，它是一种专门的神经网络，用于处理具有像 2D 矩阵（matrix）一样的图像的输入形状的数据。\n",
    "\n",
    "CNN 通常用于图像检测和分类。图像是二维像素矩阵，我们在其上运行 CNN 来识别图像或对图像进行分类。识别图像是人、汽车还是地址上的数字。\n",
    "\n",
    "### 什么是卷积？\n",
    "\n",
    "卷积是一种数学运算，我们有一个输入(Input)  `I` 和一个参数 `内核(Kernel) K` 来产生一个输出，该输出表示一个形状如何被另一个修改。\n",
    "\n",
    "我们有一个图像“x”，它是具有不同颜色通道（红色、绿色和蓝色-RGB）的二维像素阵列，我们有一个特征检测器(feature detector)或内核“w”，然后我们在应用数学运算后得到的输出是称为特征图(Feature Map)\n",
    "\n",
    "![Convolution function](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/uId9sJ.jpg)\n",
    "\n",
    "\n",
    "数学运算有助于计算两个信号的相似性。\n",
    "我们可能有一个特征检测器或过滤器来识别图像中的边缘，所以当我们在图像上使用这样的过滤器时，卷积操作将帮助我们识别图像中的边缘。\n",
    "\n",
    "我们通常假设卷积函数在任何地方都为零，但我们存储值的点集是有限的。这意味着在实践中，我们可以将无限求和实现为对有限数量的数组元素的求和。\n",
    "\n",
    "![I 是二维数组，K 是核卷积函数](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/6wYnUX.jpg)\n",
    "\n",
    "由于卷积是可交换的，我们可以重写上图所示的方程，如下所示。我们这样做是为了便于在机器学习中实现，因为 m 和 n 的有效值范围变化较小。这是大多数神经网络使用的互相关函数。\n",
    "\n",
    "![Cross Correlation function](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/yvCotj.jpg)\n",
    "\n",
    "那么，我们如何在 CNN 中实现它呢？\n",
    "我们实现这一点的方式是通过卷积层\n",
    "**卷积层是 CNN 的核心构建块，它有助于特征检测。**\n",
    "\n",
    "Kernel K 是一组可学习的过滤器，与图像相比在空间上很小，但延伸到输入图像的整个深度。\n",
    "理解这一点的一个简单方法是，如果您是一名侦探，并且遇到一张大图像或黑暗中的图片，您将如何识别图像？\n",
    "您将使用手电筒扫描整个图像。这正是我们在卷积层中所做的。\n",
    "Kernel K 是一个特征检测器，相当于图像(Image) I 上的手电筒，我们正在尝试检测特征并创建多个特征图来帮助我们识别或分类图像。\n",
    "我们有多个特征检测器来帮助进行边缘检测、识别不同形状、弯曲或不同颜色等。\n",
    "这一切如何运作？\n",
    "让我们拍摄一张 5 x 5 矩阵的 3 个通道 (RGB) 的图像，一个 3 x 3 的 3 个通道 (RGB) 的特征检测器，然后将特征检测器在图像上扫描 1 步。\n",
    "\n",
    "![Feature detector will move over image by 1 stride](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/IYkttv.jpg)\n",
    "\n",
    "当我在图像上应用特征检测器时，输出矩阵或特征图的维度是多少？\n",
    "\n",
    "特征图的维度作为输入图像大小（W）、特征检测器大小（F）、步幅（S）和图像上的零填充（P）的函数是:\n",
    "\n",
    "> Dimension of the feature map as a function of the input image size(W), feature detector size(F), Stride(S) and Zero Padding on image(P) is\n",
    "\n",
    "$ \\frac {W−F+2P} {S} +1$\n",
    "\n",
    "在我们的例子中，输入图像大小 **W **是 **5**。\n",
    "特征检测器或感受视野大小为 **F**，在我们的例子中为 **3**\n",
    "步幅 (**S**) 为 1，图像上使用的零填充量 (**P**) 为 0。\n",
    "因此，我们的特征图维度将 (5–3 +0)/1 + 1=3。\n",
    "所以特征图将是一个具有三个通道（RGB）的 3*3 矩阵。\n",
    "这将在下面逐步解释：\n",
    "\n",
    "![dPPZEW](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/dPPZEW.jpg)\n",
    "\n",
    "我们看到 5 x 5 的输入图像被缩减为 3 x 3 的特征图。深度或通道保持与 3(RGB) 相同\n",
    "我们使用多个特征检测器来寻找边缘，我们可以使用特征检测器来锐化图像或模糊图像。\n",
    "如果我们不想减少特征图维度，那么我们可以使用 1 的零填充，如下所示：\n",
    "\n",
    "![UawJ06](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/UawJ06.jpg)\n",
    "\n",
    "在 5 x 5 输入图像上应用 1 的零填充（Applying a zero padding of 1 on 5 by 5 input image\n",
    "）。\n",
    "\n",
    "在这种情况下，应用相同的公式，我们得到\n",
    "(W−F+2P)/S+1 => (5–3 +2)/1 + 1=5,\n",
    "现在输出的尺寸将是 5 x 5，带有 3 个颜色通道（RGB）。\n",
    "\n",
    "### 卷积实际效果\n",
    "\n",
    "如果我们有一个 3 x 3 的特征检测器或过滤器，一个偏置单元，那么我们首先应用线性变换，如下所示：\n",
    "\n",
    "输出=输入*权重+偏差 （output= input*weight + bias）\n",
    "\n",
    "![](media/16500304803379/16500321551314.jpg)\n",
    "\n",
    "具有三个颜色通道的 5 x 5 输入图像和一个 3 x 3 的特征检测器或过滤器，带有一个偏置单元，步幅为 1\n",
    "\n",
    "参数数量 = (3 * 3 * 3 )+1 = 28\n",
    "对于 100 个特征检测器或过滤器，参数数量为 2800。\n",
    "\n",
    "在每个线性函数的卷积运算之后，我们应用 **ReLU** 激活函数。 **ReLU** 激活函数在卷积层中引入了非线性。\n",
    "\n",
    "它将特征图中的所有负像素值替换为零值。\n",
    "下图显示了应用 ReLU 激活函数后的特征图变换。\n",
    "\n",
    "![DReLcE](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/DReLcE.jpg)\n",
    "\n",
    "现在我们已经完成了局部区域的特征检测，我们将结合所有这些来自空间邻域的特征检测来构建图片。\n",
    "请记住，您是在黑暗中扫描图像的侦探，您现在已经从左到右和从上到下扫描了图像。现在我们需要结合所有特征来识别图像。\n",
    "\n",
    "### 池化（Pooling）\n",
    "\n",
    "我们现在应用池化来获得平移不变性。 （记住玫瑰图片）\n",
    "平移不变性意味着当我们对输入进行少量更改时，合并的输出不会改变。这有助于检测输入中常见的特征，例如图像中的边缘或图像中的颜色\n",
    "我们应用了最大池化功能，与最小或平均池化相比，它提供了更好的性能。\n",
    "当我们使用最大池化时，它总结了整个邻域的输出。与特征图相比，我们现在的单位更少。\n",
    "在我们的示例中，我们使用 2 x 2 的框扫描所有特征图并找到最大值。\n",
    "\n",
    "![2Ekn4p](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/2Ekn4p.jpg)\n",
    "\n",
    "使用 2 x 2 框对输出应用最大池化。黄色高亮区域的最大值为 6\n",
    "\n",
    "所以现在我们知道卷积网络有下述特点：\n",
    "\n",
    "* 并行执行多个卷积——输出是线性激活函数\n",
    "* 将非线性函数 ReLU 应用于卷积层\n",
    "* 使用像 max pooling 这样的池化函数来汇总附近位置的统计信息。这有助于“平移不变性”\n",
    "* 我们将最大池输出展平，然后将其输入到完全连接的神经网络\n",
    "\n",
    "下图是完整的卷积神经网络\n",
    "\n",
    "![1R2yJx](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/1R2yJx.jpg)\n",
    "\n",
    "是否有理由使用卷积进行图像检测？\n",
    "\n",
    "### 卷积的使用的重要思想\n",
    "\n",
    "* 稀疏交互（Sparse interactions）\n",
    "    稀疏交互或稀疏权重是通过使用小于输入图像的内核或特征检测器来实现的。\n",
    "\n",
    "    如果我们有一个大小为 256 x 256 的输入图像，那么很难检测图像中的边缘可能只占用图像中较小的像素子集。如果我们使用较小的特征检测器，那么我们可以在专注于局部特征识别时轻松识别边缘。\n",
    "    另一个优点是计算输出需要更少的操作，使其具有统计效率。\n",
    "    \n",
    "* 参数共享（Parameter sharing）\n",
    "\n",
    "    参数共享用于控制 CNN 中使用的参数或权重的数量。\n",
    "    在传统的神经网络中，每个权重只使用一次，但是在 CNN 中，我们假设如果一个特征检测器可用于计算一个空间位置，那么它可以用于计算不同的空间位置。\n",
    "当我们在 CNN 中共享参数时，它减少了要学习的参数数量，也减少了计算需求。\n",
    "\n",
    "* 等变表示（Equivariant representations）\n",
    "    \n",
    "    等变表示\n",
    "    这意味着物体检测对光照变化、位置变化是不变的，但内部表示对这些变化是等变的\n",
    "代表（玫瑰）=代表（变换（玫瑰））（represent(rose) = represent(transform(rose))）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f73c7",
   "metadata": {},
   "source": [
    "# 1. CNN 引入 - 升华\n",
    "\n",
    "## 一、CNN的引入\n",
    "\n",
    "全连接神经网络中，每相邻两层之间的每个神经元之间都是有边相连的。这样在神经元少的情况下全连接是相当不错的，但是当神经元一 旦增多的话将会导致网络参数异常的庞大。当输入层的特征维度变得很高时，这时全连接网络需要训练的参数就会增大很多，计算速度就 会变得很慢，例如一张黑白的 28×28 的手写数字图片，输入层的神经元就有784个，如下图所示：\n",
    "\n",
    "![ptgNTb](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/ptgNTb.jpg)\n",
    "\n",
    "若在中间只使用一层隐藏层，我们设定hidden layer有`15`层，此时参数 w 就有 `784×15=11760` 多个；若输入的是`28×28` 带有颜色的RGB 格式的手写数字图片，输入神经元就有`28×28×3=2352` 个…… 。这很容易看出使用全连接神经网络处理图像中的需要训练参数过多的问题。\n",
    "\n",
    "而在卷积神经网络（Convolutional Neural Network,CNN）中，卷积层的神经元只与前一层的部分神经元节点相连，即它的神经元间的连 接是非全连接的，且同一层中某些神经元之间的连接的权重 `w` 和偏移 `b` 是共享的（即相同的），这样大量地减少了需要训练参数的数量。\n",
    "\n",
    "卷积神经网络CNN的结构一般包含有：\n",
    "\n",
    "* 输入层：用于数据的输入\n",
    "* 卷积层：使用卷积核进行特征提取和特征映射\n",
    "* 激励层：由于卷积也是一种线性运算，因此需要增加非线性映射\n",
    "* 池化层：进行下采样，对特征图稀疏处理，减少数据运算量。\n",
    "* 全连接层：通常在CNN的尾部进行重新拟合，减少特征信息的损失\n",
    "* 输出层：用于输出结果\n",
    "\n",
    "当然中间还可以使用一些其他的功能层:\n",
    "\n",
    "* 归一化层（Batch Normalization）：在CNN中对特征的归一化\n",
    "* 切分层：对某些（图片）数据的进行分区域的单独学习\n",
    "* 融合层：对独立进行特征学习的分支进行融合\n",
    "\n",
    "\n",
    "## 二、CNN的层次结构\n",
    "\n",
    "\n",
    "### 输入层\n",
    "\n",
    "在CNN的输入层中，（图片）数据输入的格式 与 全连接神经网络的输入格式（一维向量）不太一样。CNN的输入层的输入格式保留了图片\n",
    "本身的结构。\n",
    "\n",
    "对于黑白的 28×28 的图片，CNN的输入是一个 28×28 的的二维神经元，如下图所示：\n",
    "\n",
    "![bVZiXD](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/bVZiXD.jpg)\n",
    "\n",
    "而对于RGB格式的28×28图片，CNN的输入则是一个 3×28×28 的三维神经元（RGB中的每一个颜色通道都有一个 28×28 的矩阵），如下图所示：\n",
    "\n",
    "![nLBiZF](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/nLBiZF.jpg)\n",
    "\n",
    "### 卷积层\n",
    "\n",
    "在卷积层中有几个重要的概念：\n",
    "\n",
    "* local receptive fields（感受视野）\n",
    "* shared weights（共享权值）\n",
    "\n",
    "假设输入的是一个 28×28 的的二维神经元，我们定义 `5×5` 的 一个 local receptive fields（感受视野），即 隐藏层的神经元与输入\n",
    "层的 `5×5` 个神经元相连，这个 `5*5` 的区域就称之为Local Receptive Fields，如下图所示：\n",
    "\n",
    "![uXGxSa](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/uXGxSa.jpg)\n",
    "\n",
    "可类似看作：隐藏层中的神经元 具有一个固定大小的感受视野去感受上一层的部分特征。在全连接神经网络中，隐藏层中的神经元的感受\n",
    "视野足够大乃至可以看到上一层的所有特征。\n",
    "\n",
    "而在卷积神经网络中，隐藏层中的神经元的感受视野比较小，只能看到上一次的部分特征，上一层的其他特征可以通过平移感受视野来得\n",
    "到同一层的其他神经元，由同一层其他神经元来看：\n",
    "\n",
    "![IIEzRG](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/IIEzRG.jpg)\n",
    "\n",
    "设移动的步长为1：从左到右扫描，每次移动 1 格，扫描完之后，再向下移动一格，再次从左到右扫描。\n",
    "\n",
    "具体过程请看：\n",
    "\n",
    "\n",
    "![](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/FCNN.gif)\n",
    "\n",
    "可看出 卷积层的神经元是只与前一层的部分神经元节点相连，每一条相连的线对应一个权重w.\n",
    "\n",
    "一个感受视野带有一个卷积核，我们将感受视野中的权重w矩阵称为卷积核将感受视野对输入的扫描间隔称为步长（stride）；\n",
    "\n",
    "当步长比较大时（stride>1），为了扫描到边缘的一些特征，感受视野可能会“出界”，这时需要对边界扩充(pad)，边界扩充可以设为0\n",
    "或其他值。步长和边界扩充值的大小由用户来定义。\n",
    "\n",
    "卷积核的大小由用户来定义，即定义的感受视野的大小；卷积核的权重矩阵的值，便是卷积神经网络的参数，为了有一个偏移项 ，卷积\n",
    "核可附带一个偏移项 b ，它们的初值可以随机来生成，可通过训练进行变化。\n",
    "\n",
    "因此感受视野(5X5)扫描时可以计算出下一层神经元的值为：\n",
    "\n",
    "$$\n",
    "b+\\sum_{i=0}^{4} \\sum_{j=0}^{4} w_{i j} x_{i j}\n",
    "$$\n",
    "\n",
    "对下一层的所有神经元来说，它们从不同的位置去探测了上一层神经元的特征。\n",
    "\n",
    "我们将通过一个带有卷积核的感受视野 扫描生成的下一层神经元矩阵 称为 一个feature map (特征映射图)，如下图的右边便是一个\n",
    "feature map：\n",
    "\n",
    "![h2c9KA](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/h2c9KA.jpg)\n",
    "\n",
    "因此在同一个feature map上的神经元使用的卷积核是相同的，因此这些神经元 shared weights，共享卷积核中的权值和附带的偏移。\n",
    "一个 feature map对应 一个卷积核，若我们使用 3 个不同的卷积核，可以输出3个feature map：（感受视野：5×5，布长stride：1）\n",
    "\n",
    "![U7kOBb](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/U7kOBb.jpg)\n",
    "\n",
    "因此在CNN的卷积层，我们需要训练的参数大大地减少到了 (5×5+1)×3=78个。\n",
    "\n",
    "假设输入的是 28×28 的RGB图片，即输入的是一个 3×28×28 的二维神经元，这时卷积核的大小不只用长和宽来表示，还有深度，\n",
    "感受视野也对应的有了深度，如下图所示：\n",
    "\n",
    "![PE4ZPM](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/PE4ZPM.jpg)\n",
    "\n",
    "\n",
    "由图可知：感受视野： 3×2×2 ； 卷积核： 3×2×2 ，深度为3；下一层的神经元的值为:\n",
    "$$\n",
    "\\mathrm{b}+\\sum_{\\mathrm{d}=0}^{2} \\sum_{\\mathrm{i}=0}^{1} \\sum_{\\mathrm{j}=0}^{1} \\mathrm{w}_{\\mathrm{di} \\mathrm{j}} \\mathrm{x}_{\\mathrm{di} \\mathrm{j}}\n",
    "$$\n",
    "\n",
    "\n",
    "卷积核的深度和感受视野的深度相同，都由输入数据来决定，长宽可由自己来设定，数目也可以由自己来设定，一个卷积核依然对应一个 feature map。\n",
    "\n",
    "### 激励层\n",
    "\n",
    "激励层主要对卷积层的输出进行一个非线性映射，因为卷积层的计算还是一种线性计算。使用的激励函数一般为ReLu函数：\n",
    "\n",
    "$f(x)=max(x,0)$\n",
    "\n",
    "卷积层和激励层通常合并在一起称为“卷积层”。\n",
    "\n",
    "\n",
    "### 池化层\n",
    "\n",
    "当输入经过卷积层时，若感受视野比较小，步长stride比较小，得到的feature map （特征图）还是比较大，可以通过池化层来对每一个\n",
    "feature map进行降维操作，输出的深度还是不变的，依然为 feature map 的个数。\n",
    "\n",
    "池化层也有一个“池化视野（filter）”来对feature map矩阵进行扫描，对“池化视野”中的矩阵值进行计算，一般有两种计算方式：\n",
    "\n",
    "* Max pooling：取“池化视野”矩阵中的最大值\n",
    "* Average pooling：取“池化视野”矩阵中的平均值\n",
    "    扫描的过程中同样地会涉及的扫描步长stride，扫描方式同卷积层一样，先从左到右扫描，结束则向下移动布长大小，再从左到右。如下\n",
    "    图示例所示：\n",
    "    \n",
    "![bSPtAN](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/bSPtAN.jpg)\n",
    "\n",
    "其中“池化视野”filter： 2×2；步长stride：2。\n",
    "\n",
    "最后可将 3 个 24×24 的 feature map 下采样得到 3 个 24×24 的特征矩阵：\n",
    "\n",
    "![JwuYe9](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/JwuYe9.jpg)\n",
    "\n",
    "### 归一化层\n",
    "\n",
    "1.Batch Normalization\n",
    "\n",
    "Batch Normalization（批量归一化）实现了在神经网络层的中间进行预处理的操作，即在上一层的输入归一化处理后再进入网络的下一\n",
    "层，这样可有效地防止“梯度弥散”，加速网络训练。\n",
    "\n",
    "Batch Normalization具体的算法如下图所示：\n",
    "\n",
    "![wCBI0Q](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/wCBI0Q.jpg)\n",
    "\n",
    "具体的Batch Normalization准备单独写一篇文章，这里就不展开了。\n",
    "\n",
    "2.Local Response Normalization\n",
    "\n",
    "近邻归一化(Local Response Normalization)的归一化方法主要发生在不同的相邻的卷积核（经过ReLu之后）的输出之间，即输入是发生\n",
    "在不同的经过ReLu之后的 feature map 中。\n",
    "\n",
    "LRN的公式如下：\n",
    "\n",
    "$$\n",
    "b(i, x, y)=\\frac{a(i, x, y)}{\\left(k+a \\sum_{j=\\max (0, i-n / 2)}^{\\min (N-1, i+n / 2)} a(j, x, y)^{2}\\right)^{\\beta}} \n",
    "$$\n",
    "\n",
    "\n",
    "其中：\n",
    "\n",
    "a(i,x,y) 表示第i个卷积核的输出（经过ReLu层）的feature map上的 (x，y) 位置上的值。\n",
    "\n",
    "b(i,x,y) 表示 a(i,x,y) 经LRN后的输出。\n",
    "\n",
    "N 表示卷积核的数量，即输入的 feature map的个数。\n",
    "\n",
    "n 表示近邻的卷积核（或feature map）个数，由自己来决定。\n",
    "\n",
    "k,α,β是超参数，由用户自己调整或决定。\n",
    "\n",
    "与BN的区别：BN依据mini batch的数据,近邻归一仅需要自己来决定，BN训练中有学习参数;BN归一化主要发生在不同的样本之间，LRN归\n",
    "一化主要发生在不同的卷积核的输出之间。\n",
    "\n",
    "\n",
    "### 切分层\n",
    "\n",
    "在一些应用中,需要对图片进行切割，独立地对某一部分区域进行单独学习。这样可以对特定部分进行通过调整 感受视野 进行力度更大的学习。\n",
    "\n",
    "### 融合层\n",
    "\n",
    "融合层可以对切分层进行融合，也可以对不同大小的卷积核学习到的特征进行融合。\n",
    "\n",
    "例如在GoogleLeNet中，使用多种分辨率的卷积核对目标特征进行学习，通过 padding 使得每一个 feature map 的长宽都一致，之后再\n",
    "将多个 feature map 在深度上拼接在一起:\n",
    "\n",
    "![jA0J40](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/jA0J40.jpg)\n",
    "\n",
    "融合的方法有几种，一种是特征矩阵之间的拼接级联，另一种是在特征矩阵进行运算 (+,−,x,max,conv)。\n",
    "\n",
    "### 全连接层和输出层\n",
    "\n",
    "全连接层主要对特征进行重新拟合，减少特征信息的丢失；输出层主要准备做好最后目标结果的输出。例如VGG的结构图，如下图所示：\n",
    "\n",
    "![gNAjwO](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/gNAjwO.png)\n",
    "\n",
    "## 三、典型的卷积神经网络\n",
    "\n",
    "### LeNet-5模型\n",
    "\n",
    "第一个成功应用于数字数字识别的卷积神经网络模型（卷积层自带激励函数，下同）：\n",
    "\n",
    "![JnwLfG](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/JnwLfG.png)\n",
    "\n",
    "卷积层的卷积核边长都是5，步长都为1；池化层的窗口边长都为2，步长都为2。\n",
    "\n",
    "### AlexNet 模型\n",
    "\n",
    "具体结构图：\n",
    "\n",
    "![AtInL8](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/AtInL8.png)\n",
    "\n",
    "从AlexNet的结构可发现：经典的卷积神经网络结构通常为：\n",
    "\n",
    "输入层 → (卷积层+→池化层？)+→全连接层+→输出层\n",
    "\n",
    "AlexNet卷积层的卷积核边长为5或3，池化层的窗口边长为3。具体参数如图所示：\n",
    "\n",
    "![GbcxCc](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/GbcxCc.jpg)\n",
    "\n",
    "### VGGNet 模型\n",
    "\n",
    "VGGNet 模型 和 AlexNet模型 在结构上没多大变化，在卷积层部位增加了多个卷积层。AlexNet（上） 和 VGGNet （下）的对比如下图所示：\n",
    "\n",
    "![vu6bpb](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/vu6bpb.png)\n",
    "\n",
    "具体参数如图所示：其中CONV3-64：表示卷积核的长和宽为3，个数有64个；POOL2：表示池化窗口的长和宽都为2，其他类似。\n",
    "\n",
    "![7fkSMg](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/7fkSMg.png)\n",
    "\n",
    "### GoogleNet 模型\n",
    "\n",
    "使用了多个不同分辨率的卷积核，最后再对它们得到的feature map 按深度融合在一起，结构如图：\n",
    "\n",
    "![Pj9ZIl](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Pj9ZIl.png)\n",
    "\n",
    "其中，有一些主要的模块称为 Inception module，例如：\n",
    "\n",
    "![BduwQw](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/BduwQw.png)\n",
    "\n",
    "在 Inception module 中使用到了很多 1×1 的卷积核，使用 1×1 的卷积核，步长为1时，输入的feature map和输出的feature map长\n",
    "宽不会发生改变，但可以通过改变 1×1 的卷积核的数目，来达到减小feature map的厚度的效果，从而做到一些训练参数的减少。\n",
    "\n",
    "GoogleNet还有一个特点就是它是全卷积结构（FCN）的，网络的最后没有使用全连接层，一方面这样可以减少参数的数目，不容易过拟合，\n",
    "一方面也带来了一些空间信息的丢失。代替全连接层的是全局平均池化（Global Average Pooling，GAP）的方法，思想是：为每一个类别\n",
    "输出一个 feature map ，再取每一个 feature map上的平均值，作为最后的softmax层的输入。\n",
    "\n",
    "### ResNet模型\n",
    "\n",
    "在前面的CNN模型中，都是将输入一层一层地传递下去（图左），当层次比较深时，模型不是很好训练。在ResNet模型中，它将低层学习到\n",
    "的特征和高层的学习到的特征进行一个融合（加法运算,图右），这样反向传递时，导数传递得更快，减少梯度弥散的现象。\n",
    "\n",
    "注意：F（X）的shape需要等于 X 的shape ，这样才可以进行相加。\n",
    "\n",
    "![r4iPbt](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/r4iPbt.png)\n",
    "\n",
    "## 四、Tensorflow代码\n",
    "\n",
    "主要的函数说明：\n",
    "\n",
    "### 卷积层\n",
    "\n",
    "\n",
    "```python\n",
    "#卷积层： \n",
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "```\n",
    "\n",
    "\n",
    "参数说明：\n",
    "\n",
    "* data_format：表示输入的格式，有两种分别为：“NHWC”和“NCHW”，默认为“NHWC”\n",
    "\n",
    "* input：输入是一个4维格式的（图像）数据，数据的 shape 由 data_format 决定：当 data_format 为“NHWC”输入数据的shape表示\n",
    "    为[batch, in_height, in_width, in_channels]，分别表示训练时一个batch的图片数量、图片高度、 图片宽度、 图像通道数。\n",
    "    当 data_format 为“NHWC”输入数据的shape表示为[batch, in_channels， in_height, in_width]\n",
    "\n",
    "* filter：卷积核是一个4维格式的数据：shape表示为：[height,width,in_channels, out_channels]，分别表示卷积核的高、宽、\n",
    "    深度（与输入的in_channels应相同）、输出 feature map的个数（即卷积核的个数）。\n",
    "\n",
    "* strides：表示步长：一个长度为4的一维列表，每个元素跟data_format互相对应，表示在data_format每一维上的移动步长。当输入的默\n",
    "    认格式为：“NHWC”，则 strides = [batch , in_height , in_width, in_channels]。其中 batch 和 in_channels 要求一定为1，\n",
    "    即只能在一个样本的一个通道上的特征图上进行移动，in_height , in_width表示卷积核在特征图的高度和宽度上移动的布长，即 \n",
    "    strideheight 和 stridewidth 。\n",
    "\n",
    "* padding：表示填充方式：“SAME”表示采用填充的方式，简单地理解为以0填充边缘，当stride为1时，输入和输出的维度相同；“VALID”\n",
    "    表示采用不填充的方式，多余地进行丢弃。\n",
    "    \n",
    "    ### 池化层\n",
    "\n",
    "```python\n",
    "#池化层： \n",
    "tf.nn.max_pool( value, ksize,strides,padding,data_format=’NHWC’,name=None) \n",
    "#or \n",
    "tf.nn.avg_pool(…)\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "\n",
    "value：表示池化的输入：一个4维格式的数据，数据的 shape 由 data_format 决定，默认情况下shape 为[batch, height, width, channels]\n",
    "\n",
    "其他参数与 tf.nn.cov2d 类型\n",
    "\n",
    "ksize：表示池化窗口的大小：一个长度为4的一维列表，一般为[1, height, width, 1]，因不想在batch和channels上做池化，则将 其值设为1。\n",
    "\n",
    "### BN层\n",
    "\n",
    "```python\n",
    "#Batch Nomalization层： \n",
    "batch_normalization( x,mean,variance,offset,scale, variance_epsilon,name=None)\n",
    "```\n",
    "参数说明：\n",
    "\n",
    "mean 和 variance 通过 tf.nn.moments 来进行计算： batch_mean, batch_var = tf.nn.moments(x, axes = [0, 1, 2], keep_dims=True)，注意axes的输入。对于以feature map 为维度的 全局归一化，若feature map 的shape 为[batch, height, width, depth]，则将axes赋值为[0, 1, 2]\n",
    "\n",
    "x 为输入的feature map 四维数据，offset、scale为一维Tensor数据，shape 等于 feature map 的深度depth。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e109f97",
   "metadata": {},
   "source": [
    "# 2. 什么是神经网络的激活函数？\n",
    "\n",
    "先决条件：建议具备一些机器学习算法的知识和对人工神经网络的基本了解。\n",
    "\n",
    "\n",
    "## 什么是神经网络的激活函数？\n",
    "\n",
    "\n",
    "激活函数有助于决定我们是否需要激活神经元。如果我们需要激发一个神经元，那么信号的强度是多少。\n",
    "\n",
    "激活函数是神经元通过神经网络处理和传递信息的机制。\n",
    "\n",
    "## 为什么我们需要神经网络中的激活函数？\n",
    "\n",
    "![单个输入和输出神经网络](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/pwqF2x.jpg)\n",
    "\n",
    "在神经网络中，z 是输入节点和节点权重加上偏差的乘积。 z 的方程看起来与线性方程非常相似，并且可以具有范围从 +infinity 到 -infinity 的值\n",
    "\n",
    "\n",
    "**如果神经元值的范围可以从 -infinity 到 + infinity，那么我们将无法决定是否需要触发神经元。**\n",
    "\n",
    "这就是激活帮助我们解决问题的地方。\n",
    "\n",
    "如果 z 本质上是线性的，那么我们将无法解决复杂的问题。这是我们使用激活函数的另一个原因。\n",
    "\n",
    "\n",
    "## 激活函数的种类\n",
    "\n",
    "有不同类型的激活函数，其中一些非常常见和流行的是：\n",
    "\n",
    "* Threshold or Binary step activation function\n",
    "* Sigmoid\n",
    "* Softmax\n",
    "* Tanh or Hyperbolic tangent\n",
    "* ReLU and\n",
    "* Leaky ReLU\n",
    "\n",
    "为什么我们需要这么多不同的激活函数，我如何决定使用哪一个？\n",
    "让我们回顾一下每个激活函数，并了解它们最适合使用的地方以及原因。这将帮助我们决定在不同场景中使用哪种激活函数。\n",
    "\n",
    "### 阈值或阶跃函数(Threshold or Binary Step function)\n",
    "\n",
    "![NSiqUr](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/NSiqUr.jpg)\n",
    "\n",
    "这是最简单的函数，可以认为是 **是或否函数**。\n",
    "\n",
    "如果 z 的值高于阈值，则激活设置为 1 或是，神经元将被激发。\n",
    "如果 z 的值低于阈值，则激活设置为 0 或否，并且不会触发神经元。\n",
    "它们对于二元分类很有用。\n",
    "\n",
    "### Sigmoid 激活函数\n",
    "\n",
    "![Qqs9is](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Qqs9is.jpg)\n",
    "\n",
    "Sigmoid 函数是一个平滑的非线性函数，没有扭结，看起来像 S 形。\n",
    "\n",
    "它可以预测输出的概率，因此用于神经网络的输出层和逻辑回归。\n",
    "\n",
    "由于概率在 0 到 1 之间，所以 sigmoid 函数值存在于 0 到 1 之间。\n",
    "\n",
    "但是，如果我们想要分类的不仅仅是是或否怎么办？如果我想预测多个类，比如预测晴天、雨天或多云的天气怎么办？\n",
    "\n",
    "Softmax 激活有助于多类分类\n",
    "\n",
    "### Softmax 激活函数\n",
    "\n",
    "Sigmoid 激活函数用于两类或二元类分类，而 Softmax 用于多类分类，是 Sigmoid 函数的推广。\n",
    "\n",
    "在 Softmax 中，我们得到每个类的概率总和应该等于1。当一个类的概率增加时，其他类的概率会减小，因此概率最高的类是输出类。\n",
    "\n",
    "示例：在预测天气时，我们可能会得到晴天的输出概率为 0.68，阴天的输出概率为 0.22，雨天的输出概率为 0.20。在这种情况下，我们将具有最大概率的输出作为最终输出。在这种情况下，我们将预测天气晴朗。\n",
    "\n",
    "Softmax 计算每个目标类的概率超过所有可能的目标类的概率。\n",
    "\n",
    "\n",
    "![FfWhFh](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/FfWhFh.jpg)\n",
    "\n",
    "\n",
    "### 双曲正切激活函数（Hyperbolic Tangent or Tanh Activation Function）\n",
    "\n",
    "![Hyperbolic tanh activation function](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/CEWV95.jpg)\n",
    "\n",
    "\n",
    "对于双曲 tanh 函数，输出以 0 为中心，输出范围在 -1 和 +1 之间。\n",
    "\n",
    "看起来与 sigmoid 非常相似。\n",
    "\n",
    "实际上双曲 tanh 是缩放的 sigmoid 函数。**与 sigmoid 相比，tanh 的梯度下降更强，因此优于 sigmoid**。\n",
    "\n",
    "tanh 的优点是负输入将被映射为强负，零输入将映射到接近零，这在 sigmoid 中不会发生，因为 sigmoid 的范围在 0 和 1 之间\n",
    "\n",
    "\n",
    "### 整流线性单元-ReLU （Rectifier Linear Unit-ReLU\n",
    "）\n",
    "\n",
    "![jhbm4s](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/jhbm4s.jpg)\n",
    "\n",
    "* ReLU本质上是非线性的，这意味着它的斜率不是恒定的。 Relu 在零附近是非线性的，但斜率为 0 或 1，因此具有有限的非线性。\n",
    "* **范围是从 0 到无穷大**\n",
    "* 当 z 为正时，ReLU 给出与输入相同的输出。\n",
    "* 当 z 为零或小于零时，它的输出为 0。因此，当输入为零或小于零时，ReLU 会关闭神经元。\n",
    "* **所有深度学习模型都使用 Relu，但它只能用于隐藏层，因为它会导致稀疏性。稀疏性是指空值或“NA”值的数量。**\n",
    "\n",
    "* **当隐藏层暴露于一系列输入值时，整流函数将导致更多的零，从而导致更少的神经元被激活，这意味着神经网络之间的交互更少。**\n",
    "* ReLU 比 sigmoid 或 tanh 更积极地打开或关闭神经元\n",
    "* Relu 面临的挑战是负值变为零会降低模型正确训练数据的能力。为了解决这个问题，我们有 Leaky ReLU\n",
    "\n",
    "\n",
    "### Leaky ReLU\n",
    "\n",
    "![v5wAmZ](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/v5wAmZ.jpg)\n",
    "\n",
    "Leaky ReLU. Value of a is usually 0.01\n",
    "\n",
    "在leaky ReLU 中，我们引入了一个小的负斜率，因此它没有零斜率。这有助于加快训练。\n",
    "Leaky ReLU 的范围从 -infinity 到 +infinity\n",
    "\n",
    "\n",
    "这将很好地理解不同的激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b53211",
   "metadata": {},
   "source": [
    "# 3. 机器学习：梯度下降\n",
    "\n",
    "本篇文章中我们会涉及到什么是梯度下降以及对它的需求。不同类型的梯度下降，它们的优缺点。\n",
    "\n",
    "## 什么是梯度下降？\n",
    "\n",
    "梯度下降是一种迭代机器学习优化算法，用于降低成本函数，以便我们拥有能够做出准确预测的模型。\n",
    "\n",
    "成本函数/Cost function (C) 或损失函数/Loss function测量模型的实际输出和预测输出之间的差异。成本函数是一个凸（convex）函数。\n",
    "\n",
    "## 为什么我们需要梯度下降？\n",
    "\n",
    "在神经网络中，我们的目标是训练模型以优化权重/weights（w）以做出更好的预测。\n",
    "我们使用梯度下降得到优化的权重。\n",
    "\n",
    "## 我们如何找到优化的权重？\n",
    "\n",
    "这最好用一个经典的下山问题来解释。\n",
    "\n",
    "![SztGtz](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/SztGtz.jpg)\n",
    "\n",
    "梯度下降类似于登山问题，寻找一座山的最低谷\n",
    "\n",
    "在登山问题中，我们想到达一座山的最低点，而我们的能见度为零。\n",
    "我们不知道我们是在山顶，还是在山中，或者非常接近底部。\n",
    "我们最好的选择是检查我们附近的地形，并确定我们需要从哪里下降才能到达底部。我们需要迭代地执行此操作，直到没有更多的下降空间，也就是我们到达底部的时候。\n",
    "我们将在文章后面讨论如果感觉我们已经到达底部（局部最低点）但山还有另一个最低点（全局最低点），我们该怎么办。\n",
    "梯度下降帮助我们在数学上解决同样的问题。\n",
    "\n",
    "**我们将神经网络的所有权重随机初始化为接近零但不为零的值。**\n",
    "\n",
    "我们计算梯度，∂c/∂ω，它是成本相对于权重的偏导数（partial derivative）。\n",
    "\n",
    "α 是学习率，有助于根据梯度下降调整权重\n",
    "\n",
    "![Vt8Qkr](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Vt8Qkr.jpg)\n",
    "\n",
    "w 是神经元的权重，α 是学习率，C 是成本，∂c/∂ω 是梯度\n",
    "\n",
    "我们需要同时更新所有神经元的权重\n",
    "\n",
    "## 学习率\n",
    "\n",
    "学习率控制着我们应该根据损失梯度调整多少权重。学习率是随机初始化的。\n",
    "学习率的值越低，收敛到全局最小值的速度就越慢。\n",
    "较高的学习率值将不允许梯度下降收敛\n",
    "由于我们的目标是最小化成本函数以找到权重的优化值，因此我们使用不同的权重运行多次迭代并计算成本以达到最小成本，如下所示\n",
    "\n",
    "![Rjc454](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Rjc454.jpg)\n",
    "\n",
    "有可能有两个不同的山底，同样的方法，我们也可以得到成本和权重之间的局部和全局最小点。\n",
    "全局最小值是整个域的最小值，局部最小值是次优值，我们得到一个相对最小值，但不是如下所示的全局最小值。\n",
    "\n",
    "![PKC1m0](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/PKC1m0.jpg)\n",
    "\n",
    "我们如何避免局部最小值并始终尝试根据全局最小值获得优化的权重？\n",
    "\n",
    "## 不同类型的梯度下降\n",
    "\n",
    "首先让我们了解不同类型的梯度下降\n",
    "\n",
    "* 批量梯度下降\n",
    "* 随机梯度下降\n",
    "* 小批量梯度下降\n",
    "\n",
    "### 批量梯度下降（Batch Gradient Descent）\n",
    "\n",
    "**在批量梯度中，我们使用整个数据集来计算梯度下降的每次迭代的成本函数的梯度，然后更新权重。**\n",
    "\n",
    "由于我们使用整个数据集来计算梯度收敛速度很慢。\n",
    "\n",
    "如果数据集很大并且包含数百万或数十亿个数据点，那么它是内存和计算密集型的。\n",
    "\n",
    "![NJT483](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/NJT483.jpg)\n",
    "\n",
    "批量梯度下降使用整个数据集计算梯度下降的每次迭代\n",
    "\n",
    "* 批量梯度下降法的优点\n",
    "    - 权重和收敛速度的理论分析很容易理解\n",
    "\n",
    "* 批量梯度下降法的缺点\n",
    "\n",
    "    - 对大型数据集的相同训练示例执行冗余计算\n",
    "    - 可能非常缓慢且难以处理，因为大型数据集可能无法放入内存中\n",
    "    - 当我们对整个数据集进行计算时，我们可以为新数据更新模型的权重\n",
    "\n",
    "### 随机梯度下降（Stochastic Gradient descent）\n",
    "\n",
    "在随机梯度下降中，我们使用单个数据点或示例来计算梯度（gradient）并在每次迭代（iteration）时更新权重。\n",
    "\n",
    "我们首先需要打乱（shuffle）数据集，以便我们得到一个完全随机的数据集。由于数据集是随机的，并且每个示例的权重都会更新，因此权重和成本函数的更新将到处乱跳，如下所示：\n",
    "\n",
    "![1IGw8Z](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/1IGw8Z.jpg)\n",
    "\n",
    "随机抽样有助于达到全局极小值，避免陷入局部极小值。\n",
    "对于非常大的数据集，学习速度更快，收敛速度也更快。\n",
    "\n",
    "* 随机梯度下降的优点\n",
    "    - 学习比批量梯度下降快得多\n",
    "    - 当我们每次提取一个训练样本进行计算时，冗余被消除\n",
    "    - 当我们每次提取一个训练样本进行计算时，可以动态更新新数据样本的权重\n",
    "\n",
    "* 随机梯度下降的缺点\n",
    "    - 由于我们经常更新权重，成本函数波动很大\n",
    "\n",
    "![BG6ktH](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/BG6ktH.jpg)\n",
    "\n",
    "### 小批量梯度下降（Mini Batch Gradient descent）\n",
    "\n",
    "小批量梯度是随机梯度下降的一种变体，其中使用小批量样本（mini-batch of samples）代替单个训练样本。\n",
    "\n",
    "小批量梯度下降法应用广泛，收敛速度快（converges faster），稳定性好（more stable）。\n",
    "\n",
    "批量大小可能因数据集而异。\n",
    "\n",
    "当我们使用不同的样本进行批处理时，它减少了权重更新的方差所带来的噪声，这有助于更快地获得更稳定的收敛（more stable converge faster）。\n",
    "\n",
    "![BQEADh](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/BQEADh.jpg)\n",
    "\n",
    "* 最小批量梯度下降法的优点\n",
    "    - 减少参数更新的方差，从而导致稳定的收敛\n",
    "    - 加快学习速度\n",
    "    - 有助于估计实际最小值的近似位置（approximate location ）\n",
    "* 小批量梯度下降的缺点\n",
    "    - 计算每个小批量的损失，因此需要在所有小批量中累积（accumulated）总损失(total loss )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc283c9c",
   "metadata": {},
   "source": [
    "# 4. 使用 Keras 构建神经网络进行分类 - 印度糖尿病的例子\n",
    "\n",
    "在这篇文章中，我们将逐步学习使用 keras 库构建神经网络进行分类的方法。\n",
    "\n",
    "![ls1QvZ](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/ls1QvZ.jpg)\n",
    "\n",
    "## 什么是 Keras？\n",
    "\n",
    "* Keras 是一个用 Python 编写的高级神经网络 API(high-level neural network API)。\n",
    "* 它能够在 Tensorflow、CNTK 或 Theano 之上(on top of)运行。\n",
    "* Keras 可以用作深度学习库。支持卷积(Convolutional)和递归神经网络(Recurrent Neural Networks)\n",
    "* 使用 Keras 进行原型制作(Prototyping)既快速又简单\n",
    "* 在 CPU 和 GPU 上无缝运行\n",
    "\n",
    "## 一个简单的二分类神经网络\n",
    "\n",
    "我们将构建一个用于二进制分类的神经网络。\n",
    "\n",
    "对于二元分类，我们将使用 [Pima Indians 糖尿病数据库](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)进行二元分类。\n",
    "\n",
    "有 768 个观测值，有 8 个输入变量和 1 个输出变量。\n",
    "\n",
    "变量名称如下：\n",
    "* 怀孕(pregnant)的次数。\n",
    "* 口服葡萄糖耐量试验中 2 小时的血浆葡萄糖浓度/Plasma glucose concentration a 2 hours in an oral glucose tolerance test。\n",
    "* 舒张压/Diastolic blood pressure  (mm Hg)。\n",
    "* 三头肌皮褶厚度/Triceps skinfold thickness（mm）。\n",
    "* 2 小时血清胰岛素/2-Hour serum insulin (mu U/ml)。\n",
    "* 体重指数/Body mass index（体重公斤/（身高米）²）。\n",
    "* 糖尿病谱系功能/Diabetes pedigree function。\n",
    "* 年龄/Age（岁）。\n",
    "* 类变量/Class variable（0 或 1）。\n",
    "\n",
    "我们将首先导入基本库 -pandas 和 numpy 以及数据可视化库 matplotlib 和 seaborn。其他库将在使用时导入。\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "```\n",
    "\n",
    "我们现在将读取文件并将数据加载到 DataFrame 数据集中\n",
    "\n",
    "```python\n",
    "dataset = pd.read_csv('pima_indian_data.csv')\n",
    "```\n",
    "\n",
    "为了更好地理解数据，让我们查看数据集的详细信息。我们需要了解列以及与每列关联的数据类型。\n",
    "\n",
    "```python\n",
    "dataset.head(2)\n",
    "```\n",
    "\n",
    "![uwe7C9](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/uwe7C9.jpg)\n",
    "\n",
    "```python\n",
    "dataset.describe(include='all')\n",
    "```\n",
    "\n",
    "![EPsJE1](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/EPsJE1.jpg)\n",
    "\n",
    "我们可以看到所有特征都是数字的，没有任何分类数据。由于我们没有任何分类变量，我们不需要分类变量的任何数据转换。\n",
    "\n",
    "我们将数据可视化以便更好地理解。我们使用 **seaborn pairplot** 绘制数据，使用属性 `hue` 将两个类以不同的颜色绘制。\n",
    "\n",
    "```python\n",
    "sns.pairplot(dataset, hue='Class')\n",
    "```\n",
    "\n",
    "![HdE1Qj](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/HdE1Qj.jpg)\n",
    "\n",
    "我们使用数据集的相关性绘制热图(heatmap)。这有助于我们消除任何可能无助于预测的特征。\n",
    "\n",
    "```python\n",
    "sns.heatmap(dataset.corr(), annot=True)\n",
    "```\n",
    "\n",
    "![tLZXxl](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/tLZXxl.jpg)\n",
    "\n",
    "我们看到所有功能都与 Class 有某种关系，因此我们保留了所有功能。血浆葡萄糖(Plasma glucose)与分类/Class（是否患有糖尿病）的关系最强。年龄(Age)和体重指数(Body Mass Index)也是强大的影响因素。\n",
    "\n",
    "现在我们了解了数据，让我们创建输入特征和目标变量，并通过预处理数据准备好将其输入到我们的神经网络中的数据。\n",
    "\n",
    "```python\n",
    "# creating input features and target variables\n",
    "X= dataset.iloc[:,0:8]\n",
    "y= dataset.iloc[:,8]\n",
    "```\n",
    "\n",
    "让我们看看我们的输入特征\n",
    "\n",
    "```python\n",
    "X.head(2)\n",
    "```\n",
    "\n",
    "![QZogTg](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/QZogTg.jpg)\n",
    "\n",
    "由于我们的输入特征处于不同的尺度(different scales)，我们需要对输入进行标准化(standardize)。\n",
    "\n",
    "```python\n",
    "#standardizing the input feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X\n",
    "```\n",
    "\n",
    "![VOcjLP](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/VOcjLP.jpg)\n",
    "\n",
    "Standardized input features\n",
    "\n",
    "我们现在将输入特征和目标变量拆分为训练数据集和测试数据集。测试数据集将占我们整个数据集的 30%。\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "```\n",
    "\n",
    "我们已经对数据进行了预处理，现在可以构建神经网络(neural network)了。\n",
    "\n",
    "我们正在使用 keras 来构建我们的神经网络。我们导入 keras 库来创建神经网络层。\n",
    "\n",
    "keras 中有两种主要的模型类型——序列(Sequential)模型和模型。我们将使用序列模型来构建我们的神经网络。\n",
    "\n",
    "我们使用 **Dense** 库来构建神经网络的输入、隐藏和输出层。\n",
    "\n",
    "```python\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "```\n",
    "\n",
    "我们有 8 个输入特征(input features)和一个目标变量(one target variable)。 2 隐藏层(Hidden layers)。每个隐藏层将有 4 个节点(nodes)。\n",
    "\n",
    "**ReLu** 将是隐藏层的激活函数。由于这是一个二元分类问题，我们将使用 **sigmoid** 作为激活函数。\n",
    "\n",
    "密集层实现\n",
    "\n",
    "**output = activation(dot(input, kernel) + bias)**\n",
    "\n",
    "kernel 是权重矩阵。内核/kernel 初始化定义了设置 Keras 层的初始随机权重的方式。\n",
    "\n",
    "随机正态初始化器生成具有正态分布的张量(Random normal initializer generates tensors with a normal distribution.)。\n",
    "\n",
    "对于均匀分布，我们可以使用随机均匀初始化器。\n",
    "\n",
    "Keras 为内核或权重以及偏置单元提供了多个初始化器。\n",
    "\n",
    "![UZ1yky](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/UZ1yky.jpg)\n",
    "\n",
    "```python\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal', input_dim=8))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "```\n",
    "\n",
    "一旦创建了不同的层，我们现在就编译神经网络。\n",
    "\n",
    "由于这是一个二元分类问题，我们使用 **binary_crossentropy** 来计算实际输出和预测输出之间的损失函数。\n",
    "\n",
    "为了优化我们的神经网络，我们使用 **Adam**。 **Adam** 代表自适应矩估计(Adaptive moment estimation.)。 **Adam** 是 **RMSProp + Momentum** 的组合。\n",
    "\n",
    "动量/Momentum 考虑了过去的梯度，以平滑梯度下降。\n",
    "\n",
    "我们使用 准确性/accuracy 作为衡量模型性能的指标(measure the performance of the model)。\n",
    "\n",
    "```python\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "```\n",
    "\n",
    "我们现在将训练数据拟合(fit out )到我们创建的模型中。我们使用 10 的 batch_size。这意味着我们每次梯度更新使用 10 个样本。\n",
    "\n",
    "我们迭代了 100 多个 epoch 来训练模型。一个 epoch 是对整个数据集的迭代。\n",
    "\n",
    "```python\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)\n",
    "```\n",
    "\n",
    "在 100 个 epoch 之后，我们得到大约 80% 的准确率\n",
    "\n",
    "![VzLBma](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/VzLBma.jpg)\n",
    "\n",
    "我们还可以使用评估函数(evaluate function)在测试模式下评估模型的损失值( loss value)和指标值(metrics values for the model).\n",
    "\n",
    "```python\n",
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model\n",
    "```\n",
    "\n",
    "我们现在预测(predict)测试数据集的输出。如果预测值(prediction)大于 0.5，则输出为 1，否则输出为 0\n",
    "\n",
    "```python\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)\n",
    "```\n",
    "\n",
    "现在是关键时刻。我们检查测试数据集的准确性\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "```\n",
    "\n",
    "![exTbah](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/exTbah.jpg)\n",
    "\n",
    "真阳性(true positive)和真阴性( true negative)的总数是测试数据集中 231 个观察值中的 179 个。所以我们对测试数据集的准确率约为 78%。\n",
    "\n",
    "使用给定的输入，我们可以以 78% 的准确率预测该人是否患有糖尿病\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec632104",
   "metadata": {},
   "source": [
    "# 5. 使用 Keras 构建强大的图像分类卷积神经网络 - 猫狗的例子\n",
    "\n",
    "我们将使用[数据集](https://www.kaggle.com/chetankv/dogs-cats-images)将图像分类为猫或狗。\n",
    "\n",
    "我已将图像存储在一个目录结构中，如下所示\n",
    "\n",
    "![8NSOmi](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/8NSOmi.jpg)\n",
    "\n",
    "构建 CNN 以对图像进行分类的高级步骤是\n",
    "\n",
    "* 通过应用内核或特征图创建卷积层\n",
    "* 为平移不变性应用 Max pool\n",
    "* 展平输入\n",
    "* 创建一个全连接的神经网络\n",
    "* 训练模型\n",
    "* 预测输出\n",
    "\n",
    "![EM3n1y](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/EM3n1y.jpg)\n",
    "\n",
    "首先，我们初始化用于构建 CNN 的神经网络\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "classifier = Sequential()\n",
    "```\n",
    "\n",
    "我们在输入图像上使用多个特征检测器或内核应用卷积(convolution)操作。特征检测器(multiple feature detector)可以用于锐化(sharpen)图像、模糊(blur)图像等。\n",
    "\n",
    "我们的输入图像是一个 64 x 64 像素的彩色图像，具有 3 个通道。\n",
    "\n",
    "我们想要 32 个特征图(feature map)，通过使用 3 x 3 内核(kernel)或特征检测器，从左到右(from left to right)的步长(stride)为 1，从上到下(from top to bottom)的步长为 1。\n",
    "激活函数是 relu - 整流器线性单元，它有助于神经网络中的非线性。\n",
    "\n",
    "```python\n",
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
    "```\n",
    "\n",
    "一旦我们有了 32 个特征图（feature maps），我们就会应用最大池化（max pooling）来实现平移不变性（translational invariance）。平移不变性是当我们改变少量输入时，输出不会改变。最大池化减少了单元格的数量（Max pooling reduces the number of cells）。\n",
    "\n",
    "池化有助于检测颜色、边缘等特征。\n",
    "对于最大池化，我们对所有 32 个特征图使用 2 x 2 矩阵的 pool_size。\n",
    "\n",
    "```python\n",
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "```\n",
    "\n",
    "我们可以再添加一个卷积层。\n",
    "\n",
    "这次我们将有 64 个特征图(feature maps)，其内核为 (3,3)。默认步幅为 (1,1)。然后我们将最大池化应用于卷积层(convolutional layers.)。\n",
    "\n",
    "```python\n",
    "classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "```\n",
    "\n",
    "下一步是展平(flatten)所有输入。展平的数据将作为全连接神经网络(fully connected neural network)的输入。\n",
    "\n",
    "```python\n",
    "from keras.layers import Flatten\n",
    "classifier.add(Flatten())\n",
    "```\n",
    "\n",
    "我们现在构建一个具有 128 个输入单元(input units )和一个输出单元(one output unit)的全连接神经网络。我们使用 20% 的 Dropout 率来防止(prevent)过拟合(overfitting)。\n",
    "\n",
    "这是一个二元分类问题，因此我们在输出层使用 sigmoid 激活函数。\n",
    "\n",
    "```python\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dropout(rate=0.2))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "我们现在用 **Adadelta** 优化器编译神经网络。 **Adadelta** 加速了收敛(convergence)。\n",
    "\n",
    "损失函数将是 **binary_crossentropy**，因为这是一个二元分类问题。\n",
    "\n",
    "```python\n",
    "classifier.compile( optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "我们通过许多随机变换(a number of random transformations)应用图像增强( image augmentation)，使 CNN 适合图像。\n",
    "\n",
    "我们缩放(zoom)图像，剪切(shear)图像并水平翻转(horizontally flip )图像。这有助于防止过度拟合(overfitting)并帮助模型更好地泛化(generalize better)。\n",
    "\n",
    "我们的原始图像包含 0-255 范围内的 RGB 系数。在给定典型学习率的情况下，这些值对于我们的模型来说太高了，无法处理。为了解决这个问题，我们通过使用 1/255 因子进行缩放来将目标值设置在 0 和 1 之间。\n",
    "\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# applying transformation to image\n",
    "train_datagen = ImageDataGenerator(\n",
    " rescale=1./255,\n",
    " shear_range=0.2,\n",
    " zoom_range=0.2,\n",
    " horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "我们创建训练集(training)和测试集(test set)。我们的目标尺寸应该与输入图像的输入尺寸（64, 64）相匹配。\n",
    "\n",
    "由于我们的数据存储在目录中，我们使用 **flow_from_directory** 方法。 flow_from_directory 从指定路径获取数据帧并生成批量增强的规范化(augmented normalized)数据。\n",
    "\n",
    "```python\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'D:\\\\ML-data\\\\dataset\\\\test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'D:\\\\ML-data\\\\dataset\\\\training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "```\n",
    "\n",
    "我们最终使用 **fit_genator** 将数据拟合到我们上面创建的 CNN 模型中。\n",
    "\n",
    "我们使用 fit_genator 时\n",
    "\n",
    "* 数据集通常太大而无法放入内存。\n",
    "* 当我们需要执行数据增强以避免过度拟合时。这增加了我们模型的泛化能力。\n",
    "\n",
    "要设置参数的值，我们可以使用以下公式，但这不是硬性规定。\n",
    "\n",
    "\n",
    "steps_per_epoch = 总训练样本(Total Training Samples)/训练批次大小 (Training Batch Size)\n",
    "validation_steps = 总验证样本(Total Validation Samples)/验证批次大小(Validation Batch Size)\n",
    "\n",
    "我们在训练数据中有 8000 张图像，我们的训练批量大小为 32，因此 steps_per_epoch 设置为 8000/32。\n",
    "\n",
    "我们在测试集中有 2000 张图像，我们的批量大小为 32，因此 validation_steps = 2000/32 四舍五入为 64。我没有得到很好的验证准确度，所以我尝试了不同的组合，然后确定为 150\n",
    "\n",
    "```python\n",
    "from IPython.display import display \n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=250,\n",
    "        epochs=10,\n",
    "        validation_data=test_set, validation_steps=150)\n",
    "```\n",
    "\n",
    "![Tyespx](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/Tyespx.jpg)\n",
    "\n",
    "我们在训练数据上获得了 99% 的准确率，在测试数据上获得了 77% 的准确率。\n",
    "\n",
    "我们现在终于拍摄了一张图像来进行预测。我已将狗和猫的测试图像添加到名为 single_prediction 的数据集下的新文件夹中。\n",
    "\n",
    "![ki00V4](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/ki00V4.jpg)\n",
    "\n",
    "我们如何确定 0 是代表猫还是狗？\n",
    "\n",
    "我们使用 class_indices 作为 training_set 来理解 0 和 1 代表什么。\n",
    "\n",
    "```python\n",
    "training_set.class_indices\n",
    "```\n",
    "\n",
    "![XuhIPt](https://upiclw.oss-cn-beijing.aliyuncs.com/uPic/XuhIPt.jpg)\n",
    "\n",
    "如果输出为 0，则图像是猫，如果输出为 1，则图像是狗。\n",
    "\n",
    "我们如何对图像进行预测？\n",
    "\n",
    "我们需要对测试图像输入进行整形，以使预测方法正常工作。\n",
    "\n",
    "**test_image** 是一个 **64 x 64** 像素的输入。我们首先需要为颜色添加 3 个通道，以匹配我们为第一个卷积层指定的输入形状。为此，我们使用 Keras 的图像库。将 img_to_array() 方法应用于 test_image 后，它的维度为 (64, 64, 3)\n",
    "\n",
    "**Predict** 方法还需要一个 **batch_size**，它是输入图像的第一个维度。\n",
    "\n",
    "Batch_size 指定我们将发送到 predict 方法的图像数量。在我们的示例中，我们只发送一张图像，但我们仍然需要指定它。\n",
    "\n",
    "test_image 的最终尺寸为 (1, 64, 64, 3)\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(\"D:\\\\ML-data\\\\dataset\\\\single_prediction\\\\cat_or_dog_1.jpg\",target_size=(64, 64) )\n",
    "# Adding the channel\n",
    "test_image = image.img_to_array(test_image)\n",
    "# adding the batch size as predict method expects\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "# Predicting the test image\n",
    "result= classifier.predict(test_image)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "\n",
    "我们得到的结果是 1，这意味着狗被正确分类的第一张图像。\n",
    "\n",
    "我们可以通过添加更多的卷积层或增加全连接层的深度来进一步微调模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bc21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
